{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will train the triphone HMM-GMM with delta feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaldi root directory was not found in system PATH. You can appoint it:\n",
      "exkaldi.info.reset_kaldi_root( yourPath )\n",
      "If not, ERROR will occur when implementing some core functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = \"librispeech_dummy\"\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/khanh/workspace/miniconda3/envs/kaldi/lib/;/home/khanh/workspace/miniconda3/envs/test/lib/\"\n",
    "\n",
    "import exkaldi\n",
    "exkaldi.info.reset_kaldi_root(\"/home/khanh/workspace/projects/kaldi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, instantiate a triphone model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.TriphoneHMM at 0x7f1f1805a5b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = exkaldi.hmm.TriphoneHMM()\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model___ is unavaliable now. We have to initialize its data. We will use these files which have been generated in early steps.\n",
    "\n",
    "___tree___ and ___treeStats___ : generated in 6_train_decision_tree  \n",
    "___topo___:  generated in 5_train_mono_HMM-GMM\n",
    "\n",
    "Actually, you can initialize the TriphoneHMM object from feature directly, but here we use tree statistics file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"tree\")\n",
    "treeStatsFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"treeStats.acc\")\n",
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=272, transitionIds=698, transitionStates=349, dimension=39, gaussians=272)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initialize(tree=treeFile, treeStatsFile=treeStatsFile, topoFile=topoFile)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training steps of triphone HMM are almost the same as monophone HMM except that we don't use equally aligning at the first time.\n",
    "\n",
    "We will introduce the traing step in a nutshell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training in detail\n",
    "\n",
    "At the first step, we must generate the new alignment data in the first step. You can convert the lastest alignment data generated by monophone model to a new alignment data corresponding to triphone. Use the generated alignment and final monophone model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aliFile = os.path.join(dataDir, \"exp\", \"train_mono\", \"final.ali\")\n",
    "monoFile= os.path.join(dataDir, \"exp\", \"train_mono\", \"final.mdl\")\n",
    "ali = exkaldi.load_ali(aliFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.BytesAliTrans at 0x7f1efb71da30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newAli = exkaldi.hmm.convert_alignment(\n",
    "                                 ali=ali, \n",
    "                                 originHmm=monoFile, \n",
    "                                 targetHmm=model, \n",
    "                                 tree=treeFile\n",
    "                            )\n",
    "newAli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another way, align feature again directly with new triphone model. \n",
    "\n",
    "In the next steps, we will review the steps to train a HMM-GMM model and use it to align acoustic feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del newAli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a lexicons (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.graph.LexiconBank at 0x7f1efb872f70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.load_lex(lexFile)\n",
    "\n",
    "lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare int-format transcription (generated in 5_train_mono_HMM-GMM )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '201 875 800 1004 744 653 1239 800 1004 744 725 671 1395 1268 96 751 1064 328 348 648 4 724 588 501 1416 36 53 687 367 53 1314 177 4 168'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans = exkaldi.load_transcription(intTransFile)\n",
    "\n",
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare L.fst file (generated in 3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare feature (generated in 2_feature_processing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"train_mfcc_cmvn.ark\")\n",
    "feat = exkaldi.load_feat(featFile)\n",
    "feat = feat.add_delta(order=2)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Compile new train graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, pathIsFile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_delta/train_graph'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model.compile_train_graph(tree=treeFile, transcription=trans, LFile=Lfile, outFile=trainGraphFile, lexicons=lexicons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Align acoustic feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.BytesAliTrans at 0x7f1efb103040>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model.align(feat, trainGraphFile, lexicons=lexicons)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Accumulate statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_delta/stats.acc'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model.accumulate_stats(feat=feat, ali=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Update HMM-GMM parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=272, transitionIds=698, transitionStates=349, dimension=39, gaussians=300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetGaussians = 300\n",
    "\n",
    "model.update(statsFile, targetGaussians)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training in high-level\n",
    "\n",
    "In this step, we will introduce how to training the triphone in directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del ali\n",
    "del trans\n",
    "\n",
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some file paths or objects defined above will be used here. \n",
    "\n",
    "Firstly, initialize model. Give lexicons as a optional parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=272, transitionIds=698, transitionStates=349, dimension=39, gaussians=272)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = exkaldi.hmm.TriphoneHMM(lexicons=lexicons)\n",
    "\n",
    "model.initialize(tree=treeFile, treeStatsFile=treeStatsFile, topoFile=topoFile)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train triphone model.\n",
      "Start Time: 2022/09/01-20:37:46\n",
      "Convert transcription to int value format.\n",
      "Compiling training graph.\n",
      "Iter >> 1\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 2.6693 seconds\n",
      "Iter >> 2\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 2.6164 seconds\n",
      "Iter >> 3\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 2.9060 seconds\n",
      "Iter >> 4\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.2197 seconds\n",
      "Iter >> 5\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.0789 seconds\n",
      "Iter >> 6\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.7173 seconds\n",
      "Iter >> 7\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.1027 seconds\n",
      "Iter >> 8\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.1756 seconds\n",
      "Iter >> 9\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.7712 seconds\n",
      "Iter >> 10\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.3125 seconds\n",
      "Align last time with final model\n",
      "Done to train the triphone model\n",
      "Saved Final Model: librispeech_dummy/exp/train_delta/final.mdl\n",
      "Saved Ali:  librispeech_dummy/exp/train_delta/final.ali\n",
      "End Time: 2022/09/01-20:38:21\n"
     ]
    }
   ],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\")\n",
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "\n",
    "aliIndex = model.train(feat=feat, transcription=transFile, LFile=Lfile, tree=treeFile, tempDir=outDir, \n",
    "                         numIters=10, maxIterInc=8, totgauss=1500\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment have been saved in file automatically. Look the final model information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=272, transitionIds=698, transitionStates=349, dimension=39, gaussians=1650)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
