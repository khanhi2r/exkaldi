{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ExKaldi\n",
    "\n",
    "In this section, we will training a DNN acoustic model with __Tensorflow 2.x__.\n",
    "\n",
    "If you want run this step, please install Tensorflow firstly.  \n",
    "In this tutorial, we will customize the training loop with out using \"__fit__\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaldi root directory was not found in system PATH. You can appoint it:\n",
      "exkaldi.info.reset_kaldi_root( yourPath )\n",
      "If not, ERROR will occur when implementing some core functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = \"librispeech_dummy\"\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/khanh/workspace/miniconda3/envs/kaldi/lib/;/home/khanh/workspace/miniconda3/envs/test/lib/\"\n",
    "\n",
    "import exkaldi\n",
    "exkaldi.info.reset_kaldi_root(\"/home/khanh/workspace/projects/kaldi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use keras to build and train model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "Restorage the training feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"train_mfcc_cmvn.ark\")\n",
    "feat = exkaldi.load_feat(featFile)\n",
    "feat = feat.add_delta(order=2)\n",
    "feat = feat.splice(left=1,right=1)\n",
    "feat = feat.to_numpy()\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___feat___ is an exkaldi __NumpyFeat__ object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is made following these steps:\n",
    "\n",
    "    compute mfcc (13) >> apply CMVN (13) >> add 2 order deltas (39) >> splice 1-1 frames (117)\n",
    "\n",
    "We still further do global standerd normalization on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat.normalize(std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Them we load the alignment data. They have been generated in early step (07_train_triphone_HMM-GMM_delta).\n",
    "\n",
    "We will use pdf-ID as target label. In exkaldi, transition-ID and phone-ID can also be extracted for mutiple tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.NumpyAliPdf at 0x7f09f0284340>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aliFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.ali\")\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")\n",
    "\n",
    "ali = exkaldi.load_ali(aliFile)\n",
    "\n",
    "ali = ali.to_numpy(aliType=\"pdfID\", hmm=hmmFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alignment will be label date to train the NN model.\n",
    "\n",
    "Then we tuple the feature and alignment in order to generate a dataset for deep learning framework. We use __tuple_data(...)__ function to group them. \n",
    "\n",
    "But note that, this function will group the archives by their name, so please ensure their names are avaliable as python identifiers. (that means, we only allow lower and upper letters, digits, and underline in their names.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129328"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat.rename(\"mfcc\")\n",
    "ali.rename(\"pdfID\")\n",
    "\n",
    "dataset = exkaldi.tuple_dataset([feat,ali], frameLevel=True)\n",
    "\n",
    "datasetSize = len(dataset)\n",
    "datasetSize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___dataset___ is a list. whose members are namedtuples. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TupledData(key='103-1240-0000', frameID=0, mfcc=array([[-8.1976879e-01, -1.9850516e-01,  6.3038737e-01,  9.0955116e-02,\n",
       "         8.7195081e-01,  1.2406298e+00,  1.1615741e+00,  3.2836774e-01,\n",
       "         4.5308763e-01,  6.5059960e-02,  2.0171395e-01,  6.1103612e-01,\n",
       "         3.3649167e-01,  6.7091221e-04,  2.5476824e-02,  1.7797188e-01,\n",
       "         1.7894910e-01,  4.5316700e-02, -5.1516163e-01, -4.1636893e-01,\n",
       "         2.9141966e-01,  6.8266052e-01,  5.2522767e-01, -3.1561017e-01,\n",
       "        -2.7952522e-01,  1.5361856e-01,  2.5082199e-02,  3.9682295e-02,\n",
       "         2.3468968e-01, -2.3263440e-01,  3.4785096e-02, -6.7042999e-02,\n",
       "        -1.5004002e-01, -1.2814204e-01,  4.1532350e-01,  6.2387514e-01,\n",
       "        -1.9245759e-01, -1.8295710e-01, -5.5213046e-01, -8.1962723e-01,\n",
       "        -1.9862096e-01,  6.3036972e-01,  9.1023326e-02,  8.7193406e-01,\n",
       "         1.2405851e+00,  1.1615763e+00,  3.2848203e-01,  4.5308581e-01,\n",
       "         6.4929694e-02,  2.0160693e-01,  6.1108011e-01,  3.3655649e-01,\n",
       "         7.0473336e-04,  2.5482599e-02,  1.7800866e-01,  1.7888770e-01,\n",
       "         4.5286782e-02, -5.1517093e-01, -4.1633010e-01,  2.9146150e-01,\n",
       "         6.8264365e-01,  5.2519631e-01, -3.1558836e-01, -2.7953506e-01,\n",
       "         1.5363953e-01,  2.5082733e-02,  3.9723016e-02,  2.3464718e-01,\n",
       "        -2.3260374e-01,  3.4763329e-02, -6.6995859e-02, -1.5000497e-01,\n",
       "        -1.2823628e-01,  4.1533729e-01,  6.2391531e-01, -1.9249368e-01,\n",
       "        -1.8297312e-01, -5.5214208e-01, -8.2553232e-01, -2.1918668e-01,\n",
       "         5.9499860e-01,  2.5630331e-01,  1.0390095e+00,  1.0730596e+00,\n",
       "         1.1149297e+00,  9.3187588e-01,  7.9695308e-01,  2.4121238e-01,\n",
       "        -1.5967882e-01,  2.1780245e-01,  6.7256218e-01,  1.3874488e-02,\n",
       "         1.6829044e-02,  4.8806208e-01,  1.8387648e-01,  1.7993556e-01,\n",
       "        -5.2125698e-01, -4.3074542e-01,  3.0399370e-01,  8.7585872e-01,\n",
       "         8.3593237e-01, -5.5029279e-01, -5.4969460e-01, -8.9412677e-01,\n",
       "         1.2712636e-02, -3.6308050e-02, -6.3745767e-02, -5.7964849e-01,\n",
       "         2.6480351e-02,  3.7197289e-01,  1.2698272e-01, -3.4143481e-01,\n",
       "        -1.7823859e-01,  2.2738199e-01,  1.5158108e-01,  4.3648598e-01,\n",
       "        -4.7361782e-01]], dtype=float32), pdfID=array([0], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRecord = dataset[0]\n",
    "\n",
    "oneRecord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use name to get specified data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneRecord.pdfID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you train a sequential NN model, you may not want to tuple archieves data in __frame level__ but in __utterance level__. try to change the mode of tuple. \n",
    "\n",
    "You can tuple all kinds of exkaldi archieves such as feature, CMVN, alignment, probability, transcription and so on. And even different feature such as MFCC and fBank, different alignment such as PdfID and Phone ID, can also be grouped. For example, now we want to do multiple tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ali2 = exkaldi.load_ali(aliFile)\n",
    "\n",
    "ali2 = ali2.to_numpy(aliType=\"phoneID\", hmm=hmmFile)\n",
    "\n",
    "ali2.rename(\"phoneID\")\n",
    "\n",
    "dataset2 = exkaldi.tuple_dataset([feat,ali,ali2], frameLevel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TupledData(key='103-1240-0000', frameID=0, mfcc=array([[-8.1976879e-01, -1.9850516e-01,  6.3038737e-01,  9.0955116e-02,\n",
       "         8.7195081e-01,  1.2406298e+00,  1.1615741e+00,  3.2836774e-01,\n",
       "         4.5308763e-01,  6.5059960e-02,  2.0171395e-01,  6.1103612e-01,\n",
       "         3.3649167e-01,  6.7091221e-04,  2.5476824e-02,  1.7797188e-01,\n",
       "         1.7894910e-01,  4.5316700e-02, -5.1516163e-01, -4.1636893e-01,\n",
       "         2.9141966e-01,  6.8266052e-01,  5.2522767e-01, -3.1561017e-01,\n",
       "        -2.7952522e-01,  1.5361856e-01,  2.5082199e-02,  3.9682295e-02,\n",
       "         2.3468968e-01, -2.3263440e-01,  3.4785096e-02, -6.7042999e-02,\n",
       "        -1.5004002e-01, -1.2814204e-01,  4.1532350e-01,  6.2387514e-01,\n",
       "        -1.9245759e-01, -1.8295710e-01, -5.5213046e-01, -8.1962723e-01,\n",
       "        -1.9862096e-01,  6.3036972e-01,  9.1023326e-02,  8.7193406e-01,\n",
       "         1.2405851e+00,  1.1615763e+00,  3.2848203e-01,  4.5308581e-01,\n",
       "         6.4929694e-02,  2.0160693e-01,  6.1108011e-01,  3.3655649e-01,\n",
       "         7.0473336e-04,  2.5482599e-02,  1.7800866e-01,  1.7888770e-01,\n",
       "         4.5286782e-02, -5.1517093e-01, -4.1633010e-01,  2.9146150e-01,\n",
       "         6.8264365e-01,  5.2519631e-01, -3.1558836e-01, -2.7953506e-01,\n",
       "         1.5363953e-01,  2.5082733e-02,  3.9723016e-02,  2.3464718e-01,\n",
       "        -2.3260374e-01,  3.4763329e-02, -6.6995859e-02, -1.5000497e-01,\n",
       "        -1.2823628e-01,  4.1533729e-01,  6.2391531e-01, -1.9249368e-01,\n",
       "        -1.8297312e-01, -5.5214208e-01, -8.2553232e-01, -2.1918668e-01,\n",
       "         5.9499860e-01,  2.5630331e-01,  1.0390095e+00,  1.0730596e+00,\n",
       "         1.1149297e+00,  9.3187588e-01,  7.9695308e-01,  2.4121238e-01,\n",
       "        -1.5967882e-01,  2.1780245e-01,  6.7256218e-01,  1.3874488e-02,\n",
       "         1.6829044e-02,  4.8806208e-01,  1.8387648e-01,  1.7993556e-01,\n",
       "        -5.2125698e-01, -4.3074542e-01,  3.0399370e-01,  8.7585872e-01,\n",
       "         8.3593237e-01, -5.5029279e-01, -5.4969460e-01, -8.9412677e-01,\n",
       "         1.2712636e-02, -3.6308050e-02, -6.3745767e-02, -5.7964849e-01,\n",
       "         2.6480351e-02,  3.7197289e-01,  1.2698272e-01, -3.4143481e-01,\n",
       "        -1.7823859e-01,  2.2738199e-01,  1.5158108e-01,  4.3648598e-01,\n",
       "        -4.7361782e-01]], dtype=float32), pdfID=array([0], dtype=int32), phoneID=array([1], dtype=int32))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ali2\n",
    "del dataset2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Now we start to train DNN acoustic model. Fisrtly, design a data iterator from our provided dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDim = feat.dim\n",
    "pdfClasses = exkaldi.hmm.load_hmm(hmmFile,hmmType=\"tri\").info.pdfs\n",
    "\n",
    "del ali\n",
    "del feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generater(dataset):\n",
    "\n",
    "    length = len(dataset)\n",
    "    while True:\n",
    "        index = 0\n",
    "        random.shuffle(dataset)\n",
    "        while index < length:\n",
    "            one = dataset[index]\n",
    "            index += 1\n",
    "            yield (one.mfcc[0], one.pdfID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 15:37:24.480986: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-05 15:37:24.611922: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: \n"
     ]
    }
   ],
   "source": [
    "batchSize = 64\n",
    "tf_datasets = tf.data.Dataset.from_generator(\n",
    "                                 lambda : data_generater(dataset),\n",
    "                                 (tf.float32, tf.int32)\n",
    "                            ).batch(batchSize).prefetch(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then define a simple Dense model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DNN_model(inputsShape, classes):\n",
    "    \n",
    "    inputs = keras.Input(inputsShape)\n",
    "    h1 = keras.layers.Dense(256, activation=\"relu\", kernel_initializer=\"he_normal\")(inputs)\n",
    "    h1_bn = keras.layers.BatchNormalization()(h1)\n",
    "    \n",
    "    h2 = keras.layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\")(h1_bn)\n",
    "    h2_bn = keras.layers.BatchNormalization()(h2)\n",
    "    \n",
    "    h3 = keras.layers.Dense(512, activation=\"relu\", kernel_initializer=\"he_normal\")(h2_bn)\n",
    "    h3_bn = keras.layers.BatchNormalization()(h3)\n",
    "    \n",
    "    outputs = keras.layers.Dense(classes, use_bias=False)(h3_bn)\n",
    "    \n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 117)]             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               30208     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256)              1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               131584    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 264)               135168    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 564,736\n",
      "Trainable params: 562,176\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_DNN_model((featureDim,), pdfClasses)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are optimizer and metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "\n",
    "losses = keras.metrics.Mean(name=\"train/loss\", dtype=tf.float32)\n",
    "accs = keras.metrics.Mean(name=\"train/accuracy\", dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speecify the output dir. You can use tensorboard to check the training results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_DNN\")\n",
    "\n",
    "stamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "logDir = os.path.join(outDir, \"log\", stamp)\n",
    "file_writer = tf.summary.create_file_writer(logDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2020"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 1\n",
    "\n",
    "epoch_iterations = datasetSize//batchSize\n",
    "\n",
    "epoch_iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to print the progress bar and control the epoch ending, we will lend a hand from __tqdm__ package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[K     |████████████████████████████████| 78 kB 4.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.64.1\n"
     ]
    }
   ],
   "source": [
    "! pip install tqdm 2>/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start to train this model. During the training loop, You can use tensorboard to look the visiable training result.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=./librispeech_dummy/exp/train_DNN/log --bind_all\n",
    "```\n",
    "\n",
    "Just for fun, we do not validate the model during the training, but in real case, you should do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2020/2020 [04:18<00:00,  7.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Loss 2.133084  Acc 0.454819\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "with file_writer.as_default():\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for batch,i in zip(tf_datasets, tqdm(range(epoch_iterations))):\n",
    "            data, label = batch\n",
    "            \n",
    "            with tf.GradientTape() as tape:\n",
    "                logits = model(data, training=True)\n",
    "                loss = keras.losses.sparse_categorical_crossentropy(label, logits, from_logits=True)\n",
    "                losses(loss)\n",
    "                gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "                pred = keras.backend.argmax(logits, axis=1)\n",
    "\n",
    "                acc = exkaldi.nn.accuracy(label.numpy(), pred.numpy())\n",
    "                accs(acc.accuracy)\n",
    "        \n",
    "            #if int(optimizer.iterations.numpy()) % epoch_iterations == 0:     #<<<< if you don't use tqdm\n",
    "            #    break\n",
    "        \n",
    "        current_loss = losses.result()\n",
    "        current_acc = accs.result()\n",
    "        tf.print( f\"Epoch {epoch}\", f\" Loss {current_loss:.6f}\", f\" Acc {current_acc:.6f}\")\n",
    "\n",
    "        tf.summary.scalar(\"train/loss\", data=current_loss, step=epoch)\n",
    "        tf.summary.scalar(\"train/accuracy\", data=current_acc, step=epoch)\n",
    "\n",
    "    tf.print( \"Training Done\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model in file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "tfModelFile = os.path.join(outDir, \"dnn.h5\")\n",
    "\n",
    "model.save(tfModelFile, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we predict the network output for test data for decoding. We do the same processing as training feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "117"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeatFile = os.path.join(dataDir, \"exp\", \"test_mfcc_cmvn.ark\")\n",
    "testFeat = exkaldi.load_feat(testFeatFile)\n",
    "testFeat = testFeat.add_delta(order=2).splice(left=1,right=1)\n",
    "testFeat = testFeat.to_numpy()\n",
    "testFeat = testFeat.normalize(std=True)\n",
    "\n",
    "testFeat.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.NumpyProb at 0x7f09c58c25e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = {}\n",
    "for utt, mat in testFeat.items():\n",
    "    logits = model(mat, training=False)\n",
    "    prob[utt] = logits.numpy()\n",
    "\n",
    "prob = exkaldi.load_prob(prob)\n",
    "\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___prob___ is an exkaldi __NumpyProb__ object. Save it to file. We will decode it in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/khanh/workspace/miniconda3/envs/exkaldi/lib/python3.9/site-packages/numpy/lib/npyio.py:501: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_DNN/amp.npy'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probFile = os.path.join(outDir, \"amp.npy\")\n",
    "\n",
    "prob.save(probFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
