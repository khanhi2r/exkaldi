{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ExKaldi\n",
    "\n",
    "In this section, we will further process the Kaldi decoding lattice and score the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the lattice file (generated in 09_decode_back_HMM-GMM_and_WFST)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"decode_test\", \"test.lat\")\n",
    "\n",
    "lat = exkaldi.decode.wfst.load_lat(latFile)\n",
    "\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be simple and straightforward, we get the 1-best result from lattice. Word-id table and HMM model are necessary.\n",
    "\n",
    "Word-ID table can be __words.txt__ file (If decoded in word level) or __phones.txt__ file (If decoded in phone level) or Exkaldi __ListTable__ object.  \n",
    "\n",
    "Ideally, __LexiconBank__ object is also avaliable because you can get both \"words\" and \"phones\" from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordsFile = os.path.join(dataDir, \"exp\", \"words.txt\")\n",
    "\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_1best(symbolTable=wordsFile, hmm=hmmFile, lmwt=1, acwt=0.5)\n",
    "\n",
    "result.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___result___ is a exkaldi __Transcription__ object.\n",
    "\n",
    "The decoding result is int-ID format. If you want it by text-format, try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textResult = exkaldi.hmm.transcription_from_int(result, wordsFile)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for convenience, we restorage lexicons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.load_lex(lexFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del textResult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the __transcription_from_int__ function, we can transform transcription by using the __Transcription__'s own method, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = lexicons(\"words\")\n",
    "oovID = word2id[lexicons(\"oov\")]\n",
    "id2word = word2id.reverse()\n",
    "\n",
    "textResult = result.convert(symbolTable=id2word, unkSymbol=oovID)\n",
    "\n",
    "textResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can score the decoding result. Typically, you can compute the WER(word err rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refFile = os.path.join(dataDir, \"test\", \"text\")\n",
    "\n",
    "score = exkaldi.decode.score.wer(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or some times, compute the edit distance score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = exkaldi.decode.score.edit_distance(ref=refFile, hyp=textResult, mode=\"present\")\n",
    "\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the accuracy of words levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - score.editDistance/score.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We tested this and only get the WER 134.37, and the accuracy rate of words is 27.6%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We support further process the lattice, for example, to add penalty or to scale it.\n",
    "\n",
    "Here is a example to config different language model weight(LMWT) and penalty. (In Instead of text-format result, we use int-format reference file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refInt = exkaldi.hmm.transcription_to_int(refFile, lexicons(\"words\"), unkSymbol=lexicons(\"oov\"))\n",
    "refIntFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"decode_test\", \"text.int\")\n",
    "refInt.save(refIntFile)\n",
    "\n",
    "refInt.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for penalty in [0., 0.5, 1.0]:\n",
    "    for LMWT in range(10, 15):\n",
    "        \n",
    "        newLat = lat.add_penalty(penalty)\n",
    "        result = newLat.get_1best(lexicons(\"words\"), hmmFile, lmwt=LMWT, acwt=0.5)\n",
    "\n",
    "        score = exkaldi.decode.score.wer(ref=refInt, hyp=result, mode=\"present\")\n",
    "        \n",
    "        print(f\"Penalty {penalty}, LMWT {LMWT}: WER {score.WER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the lattice, you can get the phone-level result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phoneResult = lat.get_1best(lexicons(\"phones\"), hmmFile, lmwt=1, acwt=0.5, phoneLevel=True)\n",
    "\n",
    "phoneResult = exkaldi.hmm.transcription_from_int(phoneResult, lexicons(\"phones\"))\n",
    "\n",
    "phoneResult.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From lattice, N-Best results can also be extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        symbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                )\n",
    "\n",
    "for re in result:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___result___ is a list of N-bests __Transcription__ objects. If ___requireCost___ is True, return the LM score and AM score sumultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        symbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=True,\n",
    "                )\n",
    "\n",
    "for re in result[0]:\n",
    "    print(re.name, type(re))\n",
    "    \n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))\n",
    "\n",
    "for re in result[2]:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And importantly, Alignment can be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = lat.get_nbest(\n",
    "                        n=3,\n",
    "                        symbolTable=lexicons(\"words\"),\n",
    "                        hmm=hmmFile, \n",
    "                        acwt=0.5, \n",
    "                        phoneLevel=False,\n",
    "                        requireCost=False,\n",
    "                        requireAli=True,\n",
    "                )\n",
    "\n",
    "for re in result[1]:\n",
    "    print(re.name, type(re))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not train __LDA+MLLT__ and __SAT__ in this tutorial. If you need tutorial about them, please look the `examples` directory. We prepare some actual recipes for, for example, __TIMIT__ corpus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
