{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ExKaldi\n",
    "\n",
    "In this section, we will build a decision tree. In order to train a triphone model, a decision tree is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import exkaldi\n",
    "\n",
    "import os\n",
    "dataDir = \"librispeech_dummy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Restorage lexicons generated in early step (3_prepare_lexicons)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.load_lex(lexFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then instantiate a __DecisionTree__ object. ___lexicons___ can be provided as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = exkaldi.hmm.DecisionTree(lexicons=lexicons, contextWidth=3, centralPosition=1)\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then prepare acoustic feature, hmm model and alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"train_mfcc_cmvn.ark\")\n",
    "feat = exkaldi.load_feat(featFile)\n",
    "feat = feat.add_delta(order=2)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monophone HMM model and alignment have been generated in last step (5_train_mono_HMM-GMM). Now use them directly. In terms of all archives, that are feature, CMVN, probability, fmllr and alignment, we do not allow you use their file directly. So you need load them.\n",
    "\n",
    "You can load the data or only load the index table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_mono\", \"final.mdl\")\n",
    "\n",
    "aliFile = os.path.join(dataDir, \"exp\", \"train_mono\", \"final.ali\")\n",
    "ali = exkaldi.load_index_table(aliFile, useSuffix=\"ark\")\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As training the HMM model, we provide high-level API to train tree, but now we still introduce the training steps in detail.\n",
    "\n",
    "### Train Dicision Tree in detail\n",
    "\n",
    "#### 1. Accumulate statistics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeStatsFile = os.path.join(outDir, \"treeStats.acc\")\n",
    "\n",
    "tree.accumulate_stats(feat, hmmFile, ali, outFile=treeStatsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Cluster phones and compile questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "\n",
    "questionsFile = os.path.join(outDir, \"questions.qst\")\n",
    "\n",
    "tree.compile_questions(treeStatsFile, topoFile, outFile=questionsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Build tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLeaves = 300\n",
    "\n",
    "tree.build(treeStatsFile, questionsFile, topoFile, numLeaves=targetLeaves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision has been built done. Look it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the tree to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeFile = os.path.join(outDir, \"tree\")\n",
    "\n",
    "tree.save(treeFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, we provided a high-level API to build tree directly.\n",
    "\n",
    "### Train Dicision Tree in high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tree\n",
    "os.remove(treeStatsFile)\n",
    "os.remove(questionsFile)\n",
    "os.remove(treeFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = exkaldi.hmm.DecisionTree(lexicons=lexicons,contextWidth=3,centralPosition=1)\n",
    "\n",
    "tree.train(feat=feat, hmm=hmmFile, ali=ali, topoFile=topoFile, numLeaves=300, tempDir=outDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tree has been saved in directory automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
