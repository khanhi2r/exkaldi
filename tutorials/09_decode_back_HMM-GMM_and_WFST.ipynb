{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to Exkaldi\n",
    "\n",
    "In this section, we will decode based on HMM-GMM model and WFST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaldi root directory was not found in system PATH. You can appoint it:\n",
      "exkaldi.info.reset_kaldi_root( yourPath )\n",
      "If not, ERROR will occur when implementing some core functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = \"librispeech_dummy\"\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/khanh/workspace/miniconda3/envs/kaldi/lib/;/home/khanh/workspace/miniconda3/envs/test/lib/\"\n",
    "\n",
    "import exkaldi\n",
    "exkaldi.info.reset_kaldi_root(\"/home/khanh/workspace/projects/kaldi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare a word-id table. We use the lexicons generated in early step directly. So load it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexFile = os.path.join(dataDir, \"exp\", \"lexicons.lex\")\n",
    "\n",
    "lexicons = exkaldi.decode.graph.load_lex(lexFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In lexicons, call \"words\" to get the word-id table if you want decode in words level. Or call \"phones\" to get the phone-ID table when decoding in phone level. But both them will return the exkaldi __ListTable__ object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then prepare the acoustic feature for test. We compute the feature as same as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scpFile = os.path.join(dataDir, \"test\", \"wav.scp\")\n",
    "utt2spkFile = os.path.join(dataDir, \"test\", \"utt2spk\")\n",
    "spk2uttFile = os.path.join(dataDir, \"test\", \"spk2utt\")\n",
    "\n",
    "feat = exkaldi.compute_mfcc(scpFile, name=\"mfcc\")\n",
    "cmvn = exkaldi.compute_cmvn_stats(feat, spk2utt=spk2uttFile, name=\"cmvn\")\n",
    "feat = exkaldi.use_cmvn(feat, cmvn, utt2spk=utt2spkFile)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/test_mfcc_cmvn.ark'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"test_mfcc_cmvn.ark\")\n",
    "\n",
    "feat.save(featFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = feat.add_delta(order=2)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the HMM-GMM model and WFST decoding graph. They have been generated in early steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "HCLGFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"graph\", \"HCLG.fst\")\n",
    "\n",
    "hmmFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"final.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then decode. You can set some decoding parameters such as __beam__, __acwt__ and so on. Here we only use default configures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.decode.wfst.Lattice at 0x7f00a91b4ca0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lat = exkaldi.decode.wfst.gmm_decode(feat, hmmFile, HCLGFile, symbolTable=lexicons(\"words\"))\n",
    "\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___lat___ is an exkaldi __Lattice__ object. We will introduce it's property in detail in next step. Now, save it to file with kaldi format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_delta\", \"decode_test\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, pathIsFile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_delta/decode_test/test.lat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latFile = os.path.join(outDir,\"test.lat\")\n",
    "\n",
    "lat.save(latFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penalty 0.0, LMWT 10: WER 135.08\n",
      "Penalty 0.0, LMWT 11: WER 135.08\n",
      "Penalty 0.0, LMWT 12: WER 134.84\n",
      "Penalty 0.0, LMWT 13: WER 134.84\n",
      "Penalty 0.0, LMWT 14: WER 134.84\n",
      "Penalty 0.5, LMWT 10: WER 134.61\n",
      "Penalty 0.5, LMWT 11: WER 134.61\n",
      "Penalty 0.5, LMWT 12: WER 134.61\n",
      "Penalty 0.5, LMWT 13: WER 134.61\n",
      "Penalty 0.5, LMWT 14: WER 134.61\n",
      "Penalty 1.0, LMWT 10: WER 134.61\n",
      "Penalty 1.0, LMWT 11: WER 134.13\n",
      "Penalty 1.0, LMWT 12: WER 134.13\n",
      "Penalty 1.0, LMWT 13: WER 134.13\n",
      "Penalty 1.0, LMWT 14: WER 134.13\n"
     ]
    }
   ],
   "source": [
    "refIntFile = os.path.join(dataDir, \"exp\", \"train_delta\", \"decode_test\", \"text.int\")\n",
    "\n",
    "for penalty in [0., 0.5, 1.0]:\n",
    "    for LMWT in range(10, 15):\n",
    "    \n",
    "        newLat = lat.add_penalty(penalty)\n",
    "        result = newLat.get_1best(lexicons(\"words\"), hmmFile, lmwt=LMWT, acwt=0.5)\n",
    "\n",
    "        score = exkaldi.decode.score.wer(ref=refIntFile, hyp=result, mode=\"present\")\n",
    "        \n",
    "        print(f\"Penalty {penalty}, LMWT {LMWT}: WER {score.WER}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
