{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to ExKaldi\n",
    "\n",
    "In this section, we will train a monophone HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Kaldi root directory was not found in system PATH. You can appoint it:\n",
      "exkaldi.info.reset_kaldi_root( yourPath )\n",
      "If not, ERROR will occur when implementing some core functions.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "dataDir = \"librispeech_dummy\"\n",
    "\n",
    "os.environ[\"LD_LIBRARY_PATH\"] = \"/home/khanh/workspace/miniconda3/envs/kaldi/lib/;/home/khanh/workspace/miniconda3/envs/test/lib/\"\n",
    "\n",
    "import exkaldi\n",
    "exkaldi.info.reset_kaldi_root(\"/home/khanh/workspace/projects/kaldi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, prepare lexicons. Restorage the LexiconBank from file (Generated in step 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicons = exkaldi.load_lex(os.path.join(dataDir, \"exp\", \"lexicons.lex\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to make the HMM-GMM topology file and acoustic feature data in order to initialize a monophone GMM-HMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/topo'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topoFile = os.path.join(dataDir, \"exp\", \"topo\")\n",
    "\n",
    "exkaldi.hmm.make_topology(lexicons, outFile=topoFile, numNonsilStates=3, numSilStates=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In early step (2_feature_processing), we have made the mfcc feature, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featFile = os.path.join(dataDir, \"exp\", \"train_mfcc_cmvn.ark\")\n",
    "\n",
    "feat = exkaldi.load_feat(featFile, name=\"mfcc\")\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then add 2-order deltas to this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = feat.add_delta(order=2)\n",
    "\n",
    "feat.dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instantiate a HMM-GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.MonophoneHMM at 0x7f858c7f9430>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = exkaldi.hmm.MonophoneHMM(lexicons=lexicons, name=\"mono\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___model___ is an exkaldi __MonophoneHMM__ object. Exkaldi have two GMM-HMM APIs.\n",
    "\n",
    "__MonophoneHMM__: the monphone HMM-GMM model.  \n",
    "__TriphoneHMM__: the context-phone HMM-GMM model.  \n",
    "\n",
    "Now, this __model__ is void and unavaliable. We must initialize it's archtecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=207, transitionIds=414, transitionStates=207, dimension=39, gaussians=207)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.initialize(feat=feat, topoFile=topoFile)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we are about to train this model. We provide a high-level API, __model.train(...)__ to train this model in a nutshell, but we still introduce the basic training loop step by step here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train HMM-GMM in detail\n",
    "\n",
    "#### 1. Prepare the int-ID format transcription.\n",
    "\n",
    "We actually use the transcription with int-ID format, so it's necessary convert text format to int-ID format firstly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exkaldi.core.archive.Transcription"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transFile = os.path.join(dataDir, \"train\", \"text\")\n",
    "oov = lexicons(\"oov\")\n",
    "\n",
    "trans = exkaldi.hmm.transcription_to_int(transFile, lexicons)\n",
    "\n",
    "type(trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___trans___ is an exkaldi __Transcription__ object, which is designed to hold the transcription. We save the int-format transcription for further using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/text.int'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intTransFile = os.path.join(dataDir, \"exp\", \"text.int\")\n",
    "\n",
    "trans.save(intTransFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at this transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': '201 875 800 1004 744 653 1239 800 1004 744 725 671 1395 1268 96 751 1064 328 348 648 4 724 588 501 1416 36 53 687 367 53 1314 177 4 168'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans.subset(nHead=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compile the train graph.\n",
    "\n",
    "Compile the train graph. Here, L.fst file is necessary. In early step (3_prepare_lexicons), we have generated one, now use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lfile = os.path.join(dataDir, \"exp\", \"L.fst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though decision tree is actually useless when traing monophone HMM-GMM, Kaldi still need it. \n",
    "\n",
    "When the monophone HMM is initialized, a temporary tree is generated automatically. Use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.hmm.hmm.DecisionTree at 0x7f858c70b4f0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = model.tree\n",
    "\n",
    "tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___tree___ is an exkaldi __DecisionTree__ object. In next step, we will introduce how to build a normal decision tree. But now, skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "outDir = os.path.join(dataDir, \"exp\", \"train_mono\")\n",
    "\n",
    "exkaldi.utils.make_dependent_dirs(outDir, pathIsFile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_mono/train_graph'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainGraphFile = os.path.join(outDir, \"train_graph\")\n",
    "\n",
    "model.compile_train_graph(tree=tree, transcription=trans, LFile=Lfile, outFile=trainGraphFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When training the HMM-GMM model, a basic loop is:  \n",
    "\n",
    "    align feature >> accumulate statistics >> update gassian functions\n",
    "\n",
    "Then we introduce one training loop in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Align acoustic feature averagely in order to start the first train step.\n",
    "\n",
    "Kaldi align feature equally in the first step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.BytesAliTrans at 0x7f858c7e4940>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model.align_equally(feat, trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___ali___ is an exkaldi __BytesAliTrans__ object. It holds the alignment in transition-ID level. \n",
    "\n",
    "You can covert it to __NumPy__ format to check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': array([  8,   7,   7, ..., 255, 258, 257], dtype=int32)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali.subset(nHead=1).to_numpy().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Use alignment to accumulate the statistics in order to update the parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'librispeech_dummy/exp/train_mono/stats.acc'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statsFile = os.path.join(outDir, \"stats.acc\")\n",
    "\n",
    "model.accumulate_stats(feat=feat, ali=ali, outFile=statsFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Use these statistics to update model parameters.\n",
    "\n",
    "This step can increase the numbers of gaussians. We try to use 10 more gaussians."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=207, transitionIds=414, transitionStates=207, dimension=39, gaussians=217)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetGaussians = model.info.gaussians + 10\n",
    "\n",
    "model.update(statsFile, numgauss=targetGaussians)\n",
    "\n",
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In next training step, use Viterbi aligning to instead of average aligning.\n",
    "\n",
    "#### 6. Align acoustic feature with Vertibi algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<exkaldi.core.archive.BytesAliTrans at 0x7f8579cf0a60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali = model.align(feat=feat, trainGraphFile=trainGraphFile)\n",
    "\n",
    "ali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': array([122, 124, 123, ..., 254, 256, 258], dtype=int32)}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ali.subset(nHead=1).to_numpy().data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic training loop is just like this. Actually, we have a high-level API to train the model.\n",
    "\n",
    "### Train HMM-GMM with high-level API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(trainGraphFile)\n",
    "os.remove(statsFile)\n",
    "del ali\n",
    "del trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to train 10 iterations.\n",
    "\n",
    "Note that the text format transcription is expected when you use this method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start to train monophone model.\n",
      "Start Time: 2022/09/01-20:35:50\n",
      "Convert transcription to int value format.\n",
      "Compiling training graph.\n",
      "Iter >> 0\n",
      "Aligning data equally\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 1.4823 seconds\n",
      "Iter >> 1\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 19.2555 seconds\n",
      "Iter >> 2\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 6.1158 seconds\n",
      "Iter >> 3\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.5586 seconds\n",
      "Iter >> 4\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.1796 seconds\n",
      "Iter >> 5\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.7082 seconds\n",
      "Iter >> 6\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.6484 seconds\n",
      "Iter >> 7\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.4367 seconds\n",
      "Iter >> 8\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.7101 seconds\n",
      "Iter >> 9\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 2.8514 seconds\n",
      "Iter >> 10\n",
      "Aligning data\n",
      "Accumulate GMM statistics\n",
      "Update GMM parameters\n",
      "Used time: 3.3600 seconds\n",
      "Align last time with final model.\n",
      "Done to train the monophone model.\n",
      "Saved Final Model: librispeech_dummy/exp/train_mono/final.mdl\n",
      "Saved Alis:  librispeech_dummy/exp/train_mono/final.ali\n",
      "Saved tree: librispeech_dummy/exp/train_mono/tree\n",
      "End Time: 2022/09/01-20:36:47\n"
     ]
    }
   ],
   "source": [
    "finalAli = model.train(feat, transFile, Lfile, tempDir=outDir, numIters=10, maxIterInc=8, totgauss=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'103-1240-0000': IndexInfo(frames=1407, startIndex=0, dataSize=7056, filePath='/home/khanh/workspace/projects/exkaldi/tutorials/librispeech_dummy/exp/train_mono/final.ali'),\n",
       " '103-1240-0001': IndexInfo(frames=1593, startIndex=7056, dataSize=7986, filePath='/home/khanh/workspace/projects/exkaldi/tutorials/librispeech_dummy/exp/train_mono/final.ali'),\n",
       " '103-1240-0002': IndexInfo(frames=1393, startIndex=15042, dataSize=6986, filePath='/home/khanh/workspace/projects/exkaldi/tutorials/librispeech_dummy/exp/train_mono/final.ali'),\n",
       " '103-1240-0003': IndexInfo(frames=1469, startIndex=22028, dataSize=7366, filePath='/home/khanh/workspace/projects/exkaldi/tutorials/librispeech_dummy/exp/train_mono/final.ali'),\n",
       " '103-1240-0004': IndexInfo(frames=1250, startIndex=29394, dataSize=6271, filePath='/home/khanh/workspace/projects/exkaldi/tutorials/librispeech_dummy/exp/train_mono/final.ali')}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalAli.subset(nHead=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An __Indextable__ of final alignment object will be returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GmmHmmInfo(phones=69, pdfs=207, transitionIds=414, transitionStates=207, dimension=39, gaussians=535)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final model and alignment are saved in files automatically. You can save them manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelFile = os.path.join(outDir, \"mono.mdl\")\n",
    "#model.save(modelFile)\n",
    "#treeFile = os.path.join(outDir, \"tree\")\n",
    "#tree.save(treeFile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
